{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67c18fed-6957-4551-8033-adb587a94627",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pickle\n",
    "import pandas as pd \n",
    "import glob\n",
    "import json\n",
    "\n",
    "import graph_tool.all as gt\n",
    "from utilities import build_CI_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc477d29-81fb-41fe-9108-d51dbe92fe31",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = 'PATH TO RAW DATA'\n",
    "path_to_save = 'PATH TO RETWEETS NETWORK'\n",
    "\n",
    "users_info = 'PATH TO USERS INFO'\n",
    "save = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413f4413-8102-4118-9129-d22979b75c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The raw_data_final folder contains the rar data with all the tweets information\n",
    "# The retweet_networks_final folder contains the initial edgelists from the nhb paper\n",
    "# The edge_list_expanded foler contains the originald edgelist modifed for the tempora study. No need \n",
    "# in ensamble/validated there are the validate graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18784a55-895d-427e-b42b-de290593fdb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['right_retweet_edges.csv',\n",
       " 'right_leaning_retweet_edges.csv',\n",
       " 'left_extreme_retweet_edges.csv',\n",
       " 'center_retweet_edges.csv',\n",
       " 'fake_retweet_edges.csv',\n",
       " 'right_extreme_retweet_edges.csv',\n",
       " 'left_retweet_edges.csv',\n",
       " 'left_leaning_retweet_edges.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " glob.glob(raw_data+'/*')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87eeb59d-c038-486a-9339-ef8c6d34dbc5",
   "metadata": {},
   "source": [
    "# General case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa05c33-d54b-4cc7-9761-4696026f8e31",
   "metadata": {},
   "source": [
    "Building the general network generated by using all the categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b77b106-5545-483a-b320-59334ca4a965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "right_retweet_edges.csv\n",
      "right_leaning_retweet_edges.csv\n",
      "left_retweet_edges.csv\n",
      "left_leaning_retweet_edges.csv\n"
     ]
    }
   ],
   "source": [
    "merged_edge_list = pd.DataFrame(columns=['infl_id', 'auth_id', 'id'])\n",
    "for file_path in glob.glob(raw_data+'/*'):\n",
    "\n",
    "    print(file_path)\n",
    "    \n",
    "    # Read the edge list from the current file\n",
    "    edge_list = pd.read_csv(file_path)\n",
    "    \n",
    "    # Merge unique values based on 'id'\n",
    "    merged_edge_list = pd.concat([merged_edge_list, edge_list], ignore_index=True).drop_duplicates(subset='id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b7762b2-062c-4ea3-be13-57d2c74f3924",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_users = len(set(merged_edge_list['infl_id'].to_list()).union(merged_edge_list['auth_id'].to_list()))\n",
    "unique_edges = len(merged_edge_list['id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "725ed0b3-812d-480a-8626-ec0c8b83db10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique users  2963210\n",
      "Unique edges  48501421\n"
     ]
    }
   ],
   "source": [
    "print('Unique users ',unique_users)\n",
    "print('Unique edges ',unique_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9587795a-80e6-4ff4-b7f4-31191a13fcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create edgelist\n",
    "edgelist = merged_edge_list.groupby(['infl_id','auth_id'],as_index=False).count()\n",
    "# Rename the column 'id' to 'count'\n",
    "edgelist = edgelist.rename(columns={'id': 'weight'})\n",
    "# Create Digraph\n",
    "G = nx.from_pandas_edgelist(edgelist, 'infl_id', 'auth_id', edge_attr='weight', create_using=nx.DiGraph())\n",
    "# Save the graph as a gpickle file\n",
    "if save: \n",
    "    nx.write_gpickle(G, path_to_save+'Full_only_lr.gpickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdbd9958-98dc-419f-a9c2-e0af137ff6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is G weighted:  True\n",
      "N째 nodes:  2963210\n",
      "N째 edges:  27608480\n",
      "Weights:  48501421\n"
     ]
    }
   ],
   "source": [
    "# Some checks\n",
    "print('Is G weighted: ', nx.is_weighted(G))\n",
    "print('N째 nodes: ', len(G.nodes()))\n",
    "print('N째 edges: ', len(G.edges()))\n",
    "print('Weights: ',sum(weight['weight'] for _, _, weight in G.edges(data=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "497ce6e3-d1b2-4c0c-83ea-c480a8e141a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting ...\n"
     ]
    }
   ],
   "source": [
    " G_ = nx2gt(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c183f3f8-1c8d-4676-888e-1046cb1d2d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('v',\n",
       "  'id'): <VertexPropertyMap object with value type 'string', for Graph 0x7f11aa1e6890, at 0x7f11adfd9210>,\n",
       " ('e',\n",
       "  'weight'): <EdgePropertyMap object with value type 'double', for Graph 0x7f11aa1e6890, at 0x7f0d95b6dfd0>}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_.properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99e0bc79-a9e7-433e-8ea1-bbe4fa72dadc",
   "metadata": {},
   "outputs": [],
   "source": [
    " G_.save(path_to_save + 'Full_only_lr.gt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6125e23-ec1c-440b-920c-a9045b2767df",
   "metadata": {},
   "source": [
    "# Left vs. Right"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3c2b17-f556-4eca-96d8-712344d299b0",
   "metadata": {},
   "source": [
    "Constructing the networks for the left and right affiliations involves\n",
    "categorizing sources into distinct groups. In the case of the \"Right\" network,\n",
    "we include only those sources classified as right-leaning or falling under the right category. Conversely,\n",
    "for the \"Left\" network, we consider sources labeled as left-leaning or affiliated with the left category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e06d05d-88b1-47bd-95c1-adbcd9f91be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "right = ['right_retweet','right_leaning_retweet']\n",
    "left = ['left_retweet','left_leaning_retweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5904ed44-fa12-44c0-bbe3-8aa6f7f61dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_edge_list_right = pd.DataFrame(columns=['infl_id', 'auth_id', 'id'])\n",
    "merged_edge_list_left = pd.DataFrame(columns=['infl_id', 'auth_id', 'id'])\n",
    "for file_path in glob.glob(raw_data+'/*'):\n",
    "    net_name = file_path.split('/')[-1].split('_edges.csv')[0]\n",
    "    # Read the edge list from the current file\n",
    "    if net_name in right: \n",
    "        edge_list = pd.read_csv(file_path)\n",
    "        # Merge unique values based on 'id'\n",
    "        merged_edge_list_right = pd.concat([merged_edge_list_right, edge_list], ignore_index=True).drop_duplicates(subset='id')\n",
    "    elif net_name in left: \n",
    "        edge_list = pd.read_csv(file_path)\n",
    "        # Merge unique values based on 'id'\n",
    "        merged_edge_list_left = pd.concat([merged_edge_list_left, edge_list], ignore_index=True).drop_duplicates(subset='id')    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e113298c-972e-4b93-ab1e-a8aba04ab7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_users_right = len(set(merged_edge_list_right['infl_id'].to_list()).union(merged_edge_list_right['auth_id'].to_list()))\n",
    "unique_edges_right = len(merged_edge_list_right['id'].unique())\n",
    "\n",
    "unique_users_left = len(set(merged_edge_list_left['infl_id'].to_list()).union(merged_edge_list_left['auth_id'].to_list()))\n",
    "unique_edges_left = len(merged_edge_list_left['id'].unique())\n",
    "\n",
    "print('Unique users right',unique_users_right)\n",
    "print('Unique edges right',unique_edges_right)\n",
    "print('\\n')\n",
    "print('Unique users left',unique_users_left)\n",
    "print('Unique edges left',unique_edges_left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5456d7c5-06cf-4de7-ad6b-f75d91e15b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create edgelist\n",
    "edgelist_left = merged_edge_list_left.groupby(['infl_id','auth_id'],as_index=False).count()\n",
    "# Rename the column 'id' to 'count'\n",
    "edgelist_left = edgelist_left.rename(columns={'id': 'weight'})\n",
    "# Create Digraph\n",
    "G_left = nx.from_pandas_edgelist(edgelist_left, 'infl_id', 'auth_id', edge_attr='weight', create_using=nx.DiGraph())\n",
    "# Save the graph as a gpickle file\n",
    "if save: \n",
    "    nx.write_gpickle(G_left, path_to_save+'Left.gpickle')\n",
    "\n",
    "\n",
    "# Create edgelist\n",
    "edgelist_right = merged_edge_list_right.groupby(['infl_id','auth_id'],as_index=False).count()\n",
    "# Rename the column 'id' to 'count'\n",
    "edgelist_right = edgelist_right.rename(columns={'id': 'weight'})\n",
    "# Create Digraph\n",
    "G_right = nx.from_pandas_edgelist(edgelist_right, 'infl_id', 'auth_id', edge_attr='weight', create_using=nx.DiGraph())\n",
    "# Save the graph as a gpickle file\n",
    "if save: \n",
    "    nx.write_gpickle(G_right, path_to_save+'Right.gpickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22908844-379f-4a4a-b0fc-febad461e247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some checks\n",
    "for G in [G_left,G_right]:\n",
    "    print('Is G weighted: ', nx.is_weighted(G))\n",
    "    print('N째 nodes: ', len(G.nodes()))\n",
    "    print('N째 edges: ', len(G.edges()))\n",
    "    print('Weights: ',sum(weight['weight'] for _, _, weight in G.edges(data=True)))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf73b4b-aa10-4797-a565-df7eb07356a1",
   "metadata": {},
   "source": [
    "# Check after links validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad79f85-3f53-49d7-8d1d-f29af05e29b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "validated_networks = ['Grafo_full.pkl','Grafo_left.pkl','Grafo_right.pkl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a25a555-6b95-44ba-b79e-ace518ac0f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['Full','Left','Right']\n",
    "cnt = 0\n",
    "for V in validated_networks:\n",
    "    with open(f'VALIDATED NETWORKS PATH/{V}', \"rb\") as f:\n",
    "        V_ = pickle.load(f)\n",
    "        \n",
    "    print(f'N째 of nodes in validated graph {names[cnt]}...', len(V_.nodes()))\n",
    "    print(f'N째 of edges in validated graph {names[cnt]}...', len(V_.edges()))\n",
    "    print('\\n')\n",
    "    cnt += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
